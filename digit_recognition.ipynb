{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to train a neural network that will detect digits from 0-9. For training the neural network, MNIST (Modified National Institute of Standards and Technology database) dataset is used. The MNIST database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
    "\n",
    "MNIST dataset is provided with the keras so, you can directly use it without downloading it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 29s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# import the dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#load the data using load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is encoded as Numpy arrays. Let's look at the shape and length of these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data:  (60000, 28, 28)\n",
      "The shape of the training labels:  (60000,)\n",
      "The shape of the testing data:  (10000, 28, 28)\n",
      "The shape of the testing labels:  (10000,)\n",
      "The length of the training data:  60000\n",
      "The length of the training labels:  60000\n",
      "The length of the testing data:  10000\n",
      "The length of the testing labels:  10000\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the training data: ', train_images.shape)\n",
    "print('The shape of the training labels: ', train_labels.shape)\n",
    "print('The shape of the testing data: ', test_images.shape)\n",
    "print('The shape of the testing labels: ', test_labels.shape)\n",
    "print('The length of the training data: ', len(train_images))\n",
    "print('The length of the training labels: ', len(train_labels))\n",
    "print('The length of the testing data: ', len(test_images))\n",
    "print('The length of the testing labels: ', len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 6000 images of size 28 x 28 for training and 10000 images of size 28 x 28 for testing. The shape of the train and test labels is (6000,) which means that it is a list of labels which are mapped to each image in the train and test set respectively. \n",
    "\n",
    "Now, let's look at the contents of label arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that these labels are numbers from 0-9. Now let's first build our neural network (or the model) for this classification task. Then the above data will be fed to the model and lastly, the model will be tested on the test data to see if the model is correctly trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and layers to define the model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Sequential neural network is used\n",
    "network = models.Sequential()\n",
    "\n",
    "# let's add 2 layers to the model\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 *28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` network = models.Sequential() ``` means that the model used is Sequential. Other types of models are also there. We will look into them in other tutorials.\n",
    "\n",
    "``` network.add(layers.Dense(512, activation='relu', input_shape=(28 *28,))) ``` means that the first layer that we have added is of type Dense and it contains 512 units. They are Densely connected (also known as fully connected layers). The activation function used is relu (Rectilinear unit). The shape of the input to this layer is of the for 28 x 28\n",
    "\n",
    "``` network.add(layers.Dense(10, activation='softmax')) ``` means that this layer contains is again of type Dense and contains 10 units. The activation function used is softmax. It is a 10 way softmax layer which means that it will return an array of 10 probabilities which will sum to 1 (each probability corresponds to each class from 0 to 9)\n",
    "\n",
    "Now, let's compile the model by using appropriate optimizer, loss function and evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is ready now. We'll just need to feed the data into the model. To feed in the data, the data needs to be reshaped in the form which is expected by the model. We'd also need to convert all the values to the closed inveral [0,1]. To convert each image in the interval 0 to 1, we'd need some information about these images. Since, these images are greyscale, the maximum value must be 255 and minimum must be 0. We can also check this from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000,28*28)) # since the input to the model is of the shape 28x28\n",
    "train_images = train_images.astype('float32')/255 # model expects floating point values in 99% of the cases\n",
    "test_images = test_images.reshape((10000,28*28)) # since the input to the model is of the shape 28x28\n",
    "test_images = test_images.astype('float32')/255 # model expects floating point values in 99% of the cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also convert labels to binary categorical form. Keras provides an inbuilt function for doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data se entirely ready to be fed into the neural network. We will use fit() function to train the model. The first parameter to the following function are the training images, next argument is the label list. The named argument epoch specifies the number of iterations. Batch size defines the number of samples you want to use at one go.\n",
    "\n",
    "Note that, 1 iteration corresponds to training of all the samples not just 128 (in this case).  Batch represents the number of samples you want to use at a time. (More about it in further tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 21s 342us/step - loss: 0.2488 - acc: 0.9287\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.1027 - acc: 0.9693\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 20s 328us/step - loss: 0.0666 - acc: 0.9800\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.0485 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 20s 328us/step - loss: 0.0370 - acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f3e55ebe0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities can be seen after each iteration. Loss and the accuracy of the model. After 5 iterations, the model has achieved 98.89% accuracy. Now, let's see how is it performing on the test set. We use evaluate() function for evaluating it on the test set. The function returns the loss and the accuracy of the model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 224us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9799"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved 97.99% accuracy on the test set. This is lower than the training accuracy. This might be due to overfitting of the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
